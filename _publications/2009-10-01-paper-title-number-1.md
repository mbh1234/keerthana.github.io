---
title: "A Survey of Applications of Multi-armed bandits in the Industrial Recommender Systems"
permalink: /publication/2009-10-01-paper-title-number-1
date: 2025-06-05
author_profile: true
redirect_from:
  - /publication/2009-10-01-paper-title-number-1
---

*Under review in Journal of Machine learning (JMLR)*

**Abstract:** 

Recommender systems are used almost everywhere and are an integral part of the modern digital platforms. They significantly enhancing the user engagement and satisfaction, both of which are crucial for a successful business. Among the various approaches to recommender systems, Multi-armed bandits (MAB), a subdomain of Reinforcement learning (RL), have emerged as a highly effective tool. This paper gives a comprehensive review of MAB-based recommender systems, starting with an overview of the traditional recommender systems. We discuss the basics of MAB settings such as feature construction, reward formulation and an overview of non-contextual and contextual algorithms has be discussed. An extensive miscellaneous applications of bandits in recommender systems followed by evaluation methodologies will also be explored. Through detailed case studies and making a difference between different sectors based on their goal of recommendation, practical applications of MAB recommender systems will be shown. The paper ends with the discussion of challenges and trends for the bandit based recommender systems.
